{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa98b710",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ§  Session 2: Train Your Own Image Classifier â€” Instructor Edition\n",
    "\n",
    "Welcome, instructor! ğŸ“  \n",
    "This version of the notebook contains additional notes, teaching guidance, realâ€‘world connections, and example solutions.  \n",
    "It follows the same structure as the student notebook but with *ğŸ’¡ Instructor Tips*, *âš ï¸ Pay Attention*, and *ğŸŒ Realâ€‘World Examples* embedded throughout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d54a5",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ§  Session 2: Train Your Own Image Classifier (Beginner Level)\n",
    "\n",
    "Welcome to **Session 2** of Neweggâ€™s *AI Foundations Workshop*! ğŸ“  \n",
    "In this session, youâ€™ll **teach an AI to recognize images** â€” just like how your phone camera knows whatâ€™s a cat or a car!  \n",
    "Weâ€™ll use **PyTorch** and a fun dataset called **CIFARâ€‘10**, which contains 10 types of small color images.\n",
    "\n",
    "By the end, youâ€™ll have a mini AI model that can recognize images â€” a key skill for building your final **AI Game** in Session 4. ğŸ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2041033",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ¯ What Youâ€™ll Learn\n",
    "- How image classification works  \n",
    "- How to train and test a simple AI model  \n",
    "- How to visualize and understand model predictions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d185f0",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 1: Setup Your Environment\n",
    "Letâ€™s import the libraries we need. If any are missing, you can install them by running:\n",
    "```bash\n",
    "pip install torch torchvision matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852874eb",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ–¼ï¸ Step 2: Load and Explore the CIFARâ€‘10 Dataset\n",
    "The CIFARâ€‘10 dataset has 60,000 color images in 10 classes (airplane, car, bird, cat, etc.).  \n",
    "Each image is only 32Ã—32 pixels â€” perfect for quick training! ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform: convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download and load training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Helper function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5eea5",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§© Step 3: Build a Simple Neural Network\n",
    "Weâ€™ll build a small **Convolutional Neural Network (CNN)** â€” a type of model thatâ€™s great for recognizing images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2922a",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 4: Define Loss Function and Optimizer\n",
    "The **loss function** measures how wrong the AI is, and the **optimizer** helps it learn from mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5ec97",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸš€ Step 5: Train the Classifier\n",
    "Now weâ€™ll train the AI using the training images.  \n",
    "This will take a few minutes depending on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37555e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(2):  # run for 2 epochs for demo\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('âœ… Training complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777be118",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ” Step 6: Test the Model and See How It Performs\n",
    "Letâ€™s check how well our model learned to recognize images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e97002",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ‘€ Step 7: Visualize Model Predictions\n",
    "Letâ€™s see what our AI predicts for a few test images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:  ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681af8dd",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§ª Step 8: Try Your Own Image! (Optional)\n",
    "You can upload your own small image and let the AI guess what it is.  \n",
    "Tip: The image should look like one of the 10 categories in CIFARâ€‘10!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'  # example\n",
    "img = Image.open(requests.get(url, stream=True).raw).resize((32, 32))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "transform_single = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "\n",
    "net.eval()\n",
    "output = net(img_tensor)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"AI thinks this is a:\", classes[predicted[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d1ef5",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ‰ Step 9: Wrap-Up & Whatâ€™s Next\n",
    "Amazing work! You just trained your **first image classification model**. ğŸ†  \n",
    "In the next session, youâ€™ll learn how to build a **Chatbot** ğŸ¤– that can talk â€”  \n",
    "and later combine it with your image AI to make your **AI Guessing Game**! ğŸ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579603d",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§© Level Up! â€“ Mini Challenges\n",
    "\n",
    "Great job finishing your image classifier! ğŸ‰  \n",
    "Now, letâ€™s explore and experiment a little more. Each challenge below helps you think like an AI engineer. ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»\n",
    "\n",
    "### 1ï¸âƒ£ ğŸ§  Train Longer\n",
    "Increase the number of **epochs** in the training loop (for example, from `2` to `5` or `10`)  \n",
    "ğŸ‘‰ Does the accuracy improve? Does the training take longer?\n",
    "\n",
    "### 2ï¸âƒ£ ğŸ¨ Modify the Model\n",
    "Try changing the neural network structure â€” for example:  \n",
    "- Add another convolutional layer  \n",
    "- Change the number of filters (e.g., from 6 to 8)  \n",
    "ğŸ‘‰ Observe how these changes affect performance.\n",
    "\n",
    "### 3ï¸âƒ£ âš™ï¸ Tune the Training Parameters\n",
    "Experiment with the **learning rate** or **batch size**:  \n",
    "```python\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "```\n",
    "ğŸ‘‰ What happens if you make the learning rate smaller or larger?\n",
    "\n",
    "### 4ï¸âƒ£ ğŸ“¸ Use Your Own Images\n",
    "Collect 2â€“3 small photos from your phone or the internet (32Ã—32 pixels recommended).  \n",
    "Try running them through the model â€” does your AI guess correctly?\n",
    "\n",
    "### 5ï¸âƒ£ ğŸš€ Bonus Challenge â€“ Advanced Dataset\n",
    "Replace CIFARâ€‘10 with **CIFARâ€‘100**, which has 100 categories instead of 10!  \n",
    "Hint: You only need to change one line in the dataset loading section.  \n",
    "ğŸ‘‰ Can your network handle it?\n",
    "\n",
    "---\n",
    "\n",
    "These experiments will prepare you for **Sessionâ€¯4**, where youâ€™ll combine everything into a creative **AI Guessing Game! ğŸ®**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365c6c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ğŸ’¡ Instructor Guidance & Enrichment Notes\n",
    "\n",
    "### ğŸ§­ Session Overview\n",
    "Students will learn to train an image classifier using PyTorch and the CIFARâ€‘10 dataset.  \n",
    "Encourage curiosity and creativity â€” focus on **how machines learn patterns** rather than coding perfection.\n",
    "\n",
    "---\n",
    "## ğŸ§© Section-by-Section Instructor Notes\n",
    "\n",
    "### âš™ï¸ Step 1 â€“ Setup\n",
    "ğŸ’¡ **Tip:** If internet speed is slow, preâ€‘download the CIFARâ€‘10 dataset and store it locally on workshop machines.  \n",
    "âš ï¸ **Common Issue:** Students may run into `RuntimeError: CUDA not available`. Encourage them to switch to CPU mode â€” training will be slower but fine.\n",
    "\n",
    "---\n",
    "### ğŸ–¼ï¸ Step 2 â€“ Explore the Dataset\n",
    "ğŸŒ **Realâ€‘World Example:** Explain that image classification is the foundation for technologies like **Google Photosâ€™ search** (â€œshow me catsâ€) or **selfâ€‘driving car vision systems**.  \n",
    "ğŸ‰ **Fun Idea:** Let students vote which class (e.g., cat vs. dog) they think the AI will confuse most!\n",
    "\n",
    "---\n",
    "### ğŸ§© Step 3 â€“ Build the Neural Network\n",
    "ğŸ’¡ **Tip:** Use the analogy of the **human brain** â€” convolutional layers act like *eyes* detecting shapes and edges, while fully connected layers are the *decision-makers*.  \n",
    "âš ï¸ **Common Issue:** If students modify the number of layers or neurons, remind them to adjust the linear layer input size accordingly.\n",
    "\n",
    "---\n",
    "### ğŸš€ Step 5 â€“ Train the Model\n",
    "ğŸ’¡ **Tip:** Encourage students to notice the *loss decreasing*. Thatâ€™s like the AI â€œgetting better at learning.â€  \n",
    "ğŸŒ **Realâ€‘World Connection:** Talk about **how AI models are trained on massive image datasets** (e.g., ImageNet) and how this small CIFARâ€‘10 example is a simplified version of realâ€‘world AI training.\n",
    "\n",
    "---\n",
    "### ğŸ” Step 6 â€“ Evaluate Performance\n",
    "ğŸ‰ **Fun Activity:** Have students compare their test accuracy. Make a leaderboard!  \n",
    "ğŸ’¡ **Tip:** Discuss **overfitting** in simple terms: when an AI memorizes instead of generalizing.\n",
    "\n",
    "---\n",
    "### ğŸ§ª Step 8 â€“ Try Your Own Image\n",
    "ğŸŒ **Example:** Explain how phone apps like Snapchat filters or Amazon product scanners work using similar classification logic.  \n",
    "ğŸ’¡ **Tip:** If bandwidth allows, let students bring an image of a real object and see what the AI thinks!\n",
    "\n",
    "---\n",
    "## ğŸ† Challenge Solutions & Discussion\n",
    "\n",
    "### 1ï¸âƒ£ ğŸ§  Train Longer\n",
    "âœ… **Answer:** Accuracy usually improves slightly (e.g., from 55% â†’ 60%) with more epochs, but overfitting may appear after 10+.  \n",
    "ğŸ’¬ *Teaching Point:* More training â‰  always better â€” balance is key.\n",
    "\n",
    "### 2ï¸âƒ£ ğŸ¨ Modify the Model\n",
    "âœ… **Example:** Adding another conv layer (`nn.Conv2d(16, 32, 3)`) can boost accuracy, but increases training time.  \n",
    "ğŸ’¬ *Teaching Point:* More layers help the model â€œseeâ€ more complex features, but make sure the dataset is large enough.\n",
    "\n",
    "### 3ï¸âƒ£ âš™ï¸ Tune Parameters\n",
    "âœ… **Example:** Smaller learning rate (e.g., 0.0005) â†’ slower learning but more stable.  \n",
    "Larger rate (e.g., 0.01) â†’ faster but may overshoot.  \n",
    "ğŸ’¬ *Teaching Point:* Hyperparameter tuning is like â€œfinding the sweet spotâ€ â€” thereâ€™s no single correct value.\n",
    "\n",
    "### 4ï¸âƒ£ ğŸ“¸ Use Your Own Images\n",
    "âœ… **Solution:** Convert custom images to 32Ã—32 pixels, normalize, then test. Some images may give funny or wrong results â€” thatâ€™s normal!  \n",
    "ğŸ’¬ *Teaching Point:* Discuss why context matters â€” the AI only learned from 10 object categories.\n",
    "\n",
    "### 5ï¸âƒ£ ğŸš€ Bonus Challenge â€“ CIFARâ€‘100\n",
    "âœ… **Answer:** The same code works with `torchvision.datasets.CIFAR100`. Accuracy will drop significantly (~20%) since itâ€™s a much harder task.  \n",
    "ğŸ’¬ *Teaching Point:* Realâ€‘world AI often faces â€œCIFARâ€‘100 problemsâ€ â€” vast diversity, limited data.\n",
    "\n",
    "---\n",
    "## ğŸ“ Wrap-Up\n",
    "ğŸ¯ Reinforce key ideas:\n",
    "- AI â€œlearns from examples.â€  \n",
    "- Model performance depends on **data quality + architecture + tuning.**  \n",
    "- Encourage exploration â€” thatâ€™s how great data scientists start!\n",
    "\n",
    "ğŸ‰ **Fun Closing Idea:** Have students describe one real-world product that likely uses image classification (e.g., Tesla Autopilot, TikTok filters, airport scanners).  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
