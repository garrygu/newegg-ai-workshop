{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0d54a5",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Session 2: Train Your Own Image Classifier (Beginner Level)\n",
    "\n",
    "Welcome to **Session 2** of Newegg‚Äôs *AI Foundations Workshop*! üéì  \n",
    "In this session, you‚Äôll **teach an AI to recognize images** ‚Äî just like how your phone camera knows what‚Äôs a cat or a car!  \n",
    "We‚Äôll use **PyTorch** and a fun dataset called **CIFAR‚Äë10**, which contains 10 types of small color images.\n",
    "\n",
    "By the end, you‚Äôll have a mini AI model that can recognize images ‚Äî a key skill for building your final **AI Game** in Session 4. üéÆ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2041033",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ What You‚Äôll Learn\n",
    "- How image classification works  \n",
    "- How to train and test a simple AI model  \n",
    "- How to visualize and understand model predictions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbea07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ How Image Classification Works\n",
    "Image classification is like teaching a computer to recognize objects in photos! Here's how it works:\n",
    "\n",
    "### üì∏ 1. Input: Images\n",
    "- You give the AI thousands of photos with labels (like \"this is a cat\", \"this is a car\")\n",
    "- The AI looks at patterns in the pixels (the tiny dots that make up images)\n",
    "- It learns to recognize shapes, colors, and textures\n",
    "\n",
    "### üß† 2. Learning Process\n",
    "- The AI tries to guess what's in each image\n",
    "- When it's wrong, it adjusts its \"brain\" (neural network) to do better\n",
    "- This happens thousands of times until it gets really good at recognizing objects\n",
    "\n",
    "### üéØ 3. Making Predictions\n",
    "- You show the AI a new image it's never seen before\n",
    "- It analyzes the image and says \"I think this is a cat\" with a confidence level\n",
    "- The more it trained, the more accurate its guesses become\n",
    "\n",
    "### üåü Why This is Amazing\n",
    "- **Pattern Recognition**: AI can spot patterns humans might miss\n",
    "- **Speed**: Can analyze thousands of images in seconds\n",
    "- **Consistency**: Never gets tired or distracted like humans\n",
    "- **Scalability**: Can recognize millions of different objects\n",
    "\n",
    "**Real-World Examples**: Your phone camera recognizing faces, self-driving cars identifying traffic signs, medical AI detecting diseases in X-rays! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71709a10",
   "metadata": {},
   "source": [
    "### üé® Visual Overview: The Image Classification Process\n",
    "\n",
    "```\n",
    "üì∏ INPUT IMAGE          üß† NEURAL NETWORK          üéØ PREDICTION\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  32x32px   ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  Convolutional  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ \"This is a  ‚îÇ\n",
    "‚îÇ   Color     ‚îÇ         ‚îÇ   Layers        ‚îÇ       ‚îÇ   cat!\"     ‚îÇ\n",
    "‚îÇ   Image     ‚îÇ         ‚îÇ                 ‚îÇ       ‚îÇ             ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üìã Step-by-Step Breakdown:\n",
    "1. **üì∏ Image Input**: 32√ó32 pixel color image (like a tiny photo)\n",
    "2. **üîç Feature Detection**: Neural network finds edges, shapes, textures\n",
    "3. **üßÆ Pattern Matching**: Compares features to learned patterns\n",
    "4. **üéØ Classification**: Outputs probability for each of 10 categories\n",
    "5. **‚úÖ Final Answer**: Chooses the category with highest probability\n",
    "\n",
    "### üéÆ Why This Matters for Your AI Game:\n",
    "- **Image Recognition**: Your game can identify what players draw\n",
    "- **Smart Responses**: AI can give feedback based on what it \"sees\"\n",
    "- **Interactive Gameplay**: Makes your game more engaging and intelligent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d63a6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üõ†Ô∏è What are these libraries? (Click to Expand)</strong></summary>\n",
    "\n",
    "Let's understand what each library does in our image classification project:\n",
    "\n",
    "#### **PyTorch Core Libraries**\n",
    "- **`torch`**: The main PyTorch library - like the \"brain\" of our AI\n",
    "- **`torch.nn`**: Neural network building blocks (layers, functions)\n",
    "- **`torch.nn.functional`**: Advanced neural network functions\n",
    "- **`torch.optim`**: Optimization algorithms (how the AI learns)\n",
    "\n",
    "#### **Computer Vision Libraries**\n",
    "- **`torchvision`**: Computer vision tools and datasets\n",
    "- **`torchvision.transforms`**: Image preprocessing (resize, normalize, etc.)\n",
    "- **`torchvision.datasets`**: Ready-to-use image datasets like CIFAR-10\n",
    "\n",
    "#### **Visualization Libraries**\n",
    "- **`matplotlib.pyplot`**: For creating charts and displaying images\n",
    "- **`numpy`**: Numerical computing (handles arrays and math operations)\n",
    "\n",
    "#### **What Each Library Does**\n",
    "- **PyTorch**: The AI framework that handles neural networks\n",
    "- **torchvision**: Specialized tools for working with images\n",
    "- **matplotlib**: Makes our results visible and understandable\n",
    "- **numpy**: Handles the mathematical operations behind the scenes\n",
    "\n",
    "#### **Why We Need All of These**\n",
    "- **PyTorch**: Provides the neural network framework\n",
    "- **torchvision**: Gives us CIFAR-10 dataset and image processing tools\n",
    "- **matplotlib**: Lets us see what our AI is learning\n",
    "- **numpy**: Handles the math that makes everything work\n",
    "\n",
    "**Think of it as**: PyTorch is the engine, torchvision is the specialized tools, matplotlib is the dashboard, and numpy is the fuel! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d185f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Step 1: Setup Your Environment\n",
    "Let‚Äôs import the libraries we need. If any are missing, you can install them by running:\n",
    "```bash\n",
    "pip install torch torchvision matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067a434",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üìù What does this setup code do? (Click to Expand)</strong></summary>\n",
    "\n",
    "Let's break down each line of the setup code:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "```\n",
    "- **`import`**: Brings in the libraries we need\n",
    "- **`torch`**: Main PyTorch library for AI\n",
    "- **`torchvision`**: Computer vision tools\n",
    "- **`transforms`**: Image preprocessing functions\n",
    "- **`nn`**: Neural network building blocks\n",
    "- **`F`**: Advanced neural network functions\n",
    "- **`optim`**: Optimization algorithms\n",
    "- **`plt`**: Plotting and visualization\n",
    "- **`np`**: Numerical computing\n",
    "\n",
    "```python\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "```\n",
    "- **Purpose**: Shows which version of PyTorch we're using\n",
    "- **Why important**: Different versions might have different features\n",
    "\n",
    "```python\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "- **`torch.device`**: Creates a device object (GPU or CPU)\n",
    "- **`torch.cuda.is_available()`**: Checks if GPU is available\n",
    "- **`\"cuda\"`**: GPU (Graphics Processing Unit) - faster for AI\n",
    "- **`\"cpu\"`**: Central Processing Unit - slower but works everywhere\n",
    "- **Why this matters**: GPU can train AI much faster than CPU\n",
    "\n",
    "```python\n",
    "print(\"Using device:\", device)\n",
    "```\n",
    "- **Purpose**: Shows whether we're using GPU or CPU\n",
    "- **Why useful**: Helps us know if we're getting maximum performance\n",
    "\n",
    "#### **What is CUDA?**\n",
    "- **CUDA**: NVIDIA's technology for GPU computing\n",
    "- **GPU vs CPU**: GPU has thousands of cores, perfect for AI math\n",
    "- **Speed difference**: GPU can be 10-100x faster for AI training\n",
    "- **When to use**: Always prefer GPU for AI, CPU as backup\n",
    "\n",
    "**Real Impact**: This setup ensures we're using the fastest available hardware for our AI training! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852874eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üñºÔ∏è Step 2: Load and Explore the CIFAR‚Äë10 Dataset\n",
    "The CIFAR‚Äë10 dataset has 60,000 color images in 10 classes (airplane, car, bird, cat, etc.).  \n",
    "Each image is only 32√ó32 pixels ‚Äî perfect for quick training! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform: convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download and load training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Helper function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474766d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üìä What does this data loading code do? (Click to Expand)</strong></summary>\n",
    "\n",
    "Let's break down the data loading process step by step:\n",
    "\n",
    "#### **Image Preprocessing (Transforms)**\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "```\n",
    "- **`transforms.Compose`**: Combines multiple image transformations\n",
    "- **`ToTensor()`**: Converts images to PyTorch tensors (numbers the AI can understand)\n",
    "- **`Normalize()`**: Adjusts pixel values to be between -1 and 1 (better for AI training)\n",
    "- **Why normalize**: AI learns better when numbers are in a consistent range\n",
    "\n",
    "#### **Dataset Loading**\n",
    "```python\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "```\n",
    "- **`CIFAR10`**: A famous dataset with 60,000 images in 10 categories\n",
    "- **`root='./data'`**: Where to save the downloaded images\n",
    "- **`train=True`**: This is the training set (50,000 images)\n",
    "- **`download=True`**: Download the dataset if not already present\n",
    "- **`transform=transform`**: Apply our image preprocessing\n",
    "\n",
    "#### **Data Loader**\n",
    "```python\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "```\n",
    "- **`DataLoader`**: Organizes data into batches for efficient training\n",
    "- **`batch_size=8`**: Process 8 images at once (faster than one by one)\n",
    "- **`shuffle=True`**: Randomize image order (prevents AI from memorizing sequence)\n",
    "- **`num_workers=2`**: Use 2 CPU cores for data loading (faster)\n",
    "\n",
    "#### **CIFAR-10 Dataset Details**\n",
    "- **Total Images**: 60,000 (50,000 training + 10,000 testing)\n",
    "- **Image Size**: 32√ó32 pixels (small but perfect for learning)\n",
    "- **Categories**: 10 classes (airplane, car, bird, cat, deer, dog, frog, horse, ship, truck)\n",
    "- **Color**: RGB color images (3 color channels)\n",
    "\n",
    "#### **Why CIFAR-10 is Perfect for Learning**\n",
    "- **Small Size**: Fast to download and process\n",
    "- **Diverse**: 10 different types of objects\n",
    "- **Standard**: Used by AI researchers worldwide\n",
    "- **Realistic**: Real photos, not artificial patterns\n",
    "\n",
    "**Real Impact**: This gives us a professional-quality dataset to train our AI! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5eea5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß© Step 3: Build a Simple Neural Network\n",
    "We‚Äôll build a small **Convolutional Neural Network (CNN)** ‚Äî a type of model that‚Äôs great for recognizing images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411162a7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üß† What is a Convolutional Neural Network (CNN)? (Click to Expand)</strong></summary>\n",
    "\n",
    "A CNN is like a series of filters that help the AI understand images! Let's break it down:\n",
    "\n",
    "#### **What is a CNN?**\n",
    "- **CNN**: A type of neural network designed specifically for images\n",
    "- **Think of it as**: A stack of filters that find different features in images\n",
    "- **Why special**: Unlike regular neural networks, CNNs understand spatial relationships\n",
    "\n",
    "#### **How CNNs Work (Step by Step)**\n",
    "1. **üîç Convolutional Layers**: Find features like edges, shapes, textures\n",
    "2. **üìè Pooling Layers**: Reduce image size while keeping important features\n",
    "3. **üßÆ Fully Connected Layers**: Make final decisions about what the image is\n",
    "\n",
    "#### **Our CNN Architecture Explained**\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)      # First convolution layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)       # Pooling layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)     # Second convolution layer\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # First fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)         # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(84, 10)          # Output layer (10 categories)\n",
    "```\n",
    "\n",
    "#### **Layer by Layer Breakdown**\n",
    "- **`conv1`**: Finds basic features (edges, corners) - 3 input channels, 6 output filters\n",
    "- **`pool`**: Reduces image size by taking maximum values in 2√ó2 areas\n",
    "- **`conv2`**: Finds complex features (shapes, patterns) - 6 input, 16 output filters\n",
    "- **`fc1`**: First decision layer - 400 inputs, 120 outputs\n",
    "- **`fc2`**: Second decision layer - 120 inputs, 84 outputs\n",
    "- **`fc3`**: Final output layer - 84 inputs, 10 outputs (one for each category)\n",
    "\n",
    "#### **Why This Architecture Works**\n",
    "- **Convolutional Layers**: Learn to recognize visual features\n",
    "- **Pooling Layers**: Make the network more efficient and robust\n",
    "- **Fully Connected Layers**: Combine features to make final decisions\n",
    "- **ReLU Activation**: Adds non-linearity (makes the network more powerful)\n",
    "\n",
    "#### **Real-World Analogy**\n",
    "Think of it like a human looking at a photo:\n",
    "1. **First glance**: Notice basic shapes and edges\n",
    "2. **Second look**: Recognize more complex patterns\n",
    "3. **Final decision**: Combine all observations to identify the object\n",
    "\n",
    "**Real Impact**: This CNN can learn to recognize objects just like humans do! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2922a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Step 4: Define Loss Function and Optimizer\n",
    "The **loss function** measures how wrong the AI is, and the **optimizer** helps it learn from mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01df6c4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>‚öôÔ∏è What do loss function and optimizer do? (Click to Expand)</strong></summary>\n",
    "\n",
    "These are the \"teachers\" that help our AI learn! Let's understand how they work:\n",
    "\n",
    "#### **Loss Function (The Critic)**\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n",
    "- **Purpose**: Measures how wrong the AI's predictions are\n",
    "- **CrossEntropyLoss**: Perfect for classification tasks (choosing between categories)\n",
    "- **How it works**: Gives higher penalty for bigger mistakes\n",
    "- **Think of it as**: A teacher grading the AI's answers\n",
    "\n",
    "#### **Optimizer (The Learning Coach)**\n",
    "```python\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "```\n",
    "- **`SGD`**: Stochastic Gradient Descent - the learning algorithm\n",
    "- **`net.parameters()`**: All the weights and biases in our neural network\n",
    "- **`lr=0.001`**: Learning rate - how big steps the AI takes when learning\n",
    "- **`momentum=0.9`**: Helps the AI learn more smoothly (like momentum in physics)\n",
    "\n",
    "#### **How Learning Works**\n",
    "1. **AI makes prediction**: Looks at image, says \"I think this is a cat\"\n",
    "2. **Loss function checks**: Compares prediction to correct answer\n",
    "3. **Optimizer adjusts**: Changes the AI's \"brain\" to do better next time\n",
    "4. **Repeat**: This happens thousands of times until the AI gets good\n",
    "\n",
    "#### **Learning Rate Explained**\n",
    "- **Too high (0.1)**: AI takes big steps, might overshoot the right answer\n",
    "- **Too low (0.0001)**: AI takes tiny steps, learns very slowly\n",
    "- **Just right (0.001)**: AI learns efficiently without overshooting\n",
    "\n",
    "#### **Momentum Explained**\n",
    "- **Without momentum**: AI learns like a ball rolling down a hill\n",
    "- **With momentum**: AI learns like a ball with inertia - smoother learning\n",
    "- **Why helpful**: Prevents the AI from getting stuck in local minima\n",
    "\n",
    "**Real Impact**: These tools make our AI learn efficiently and accurately! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5ec97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Step 5: Train the Classifier\n",
    "Now we‚Äôll train the AI using the training images.  \n",
    "This will take a few minutes depending on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fcbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # run for 2 epochs for demo\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('‚úÖ Training complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56a225",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üöÄ What happens during training? (Click to Expand)</strong></summary>\n",
    "\n",
    "The training loop is where the magic happens! Let's break down each step:\n",
    "\n",
    "#### **Training Loop Breakdown**\n",
    "```python\n",
    "for epoch in range(2):  # run for 2 epochs for demo\n",
    "```\n",
    "- **Epoch**: One complete pass through all training data\n",
    "- **2 epochs**: We'll go through the dataset twice\n",
    "- **Why 2**: Quick demo - real training might use 50+ epochs\n",
    "\n",
    "#### **Inner Loop (Processing Batches)**\n",
    "```python\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "```\n",
    "- **`trainloader`**: Gives us batches of 8 images at a time\n",
    "- **`inputs`**: The images (what the AI sees)\n",
    "- **`labels`**: The correct answers (what the AI should predict)\n",
    "- **`.to(device)`**: Move data to GPU/CPU for processing\n",
    "\n",
    "#### **Forward Pass (Making Predictions)**\n",
    "```python\n",
    "optimizer.zero_grad()\n",
    "outputs = net(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "```\n",
    "- **`zero_grad()`**: Clear old gradients (start fresh)\n",
    "- **`net(inputs)`**: AI makes predictions on the images\n",
    "- **`criterion()`**: Calculate how wrong the predictions are\n",
    "\n",
    "#### **Backward Pass (Learning from Mistakes)**\n",
    "```python\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "- **`loss.backward()`**: Calculate gradients (how to improve)\n",
    "- **`optimizer.step()`**: Update the AI's weights (actually learn)\n",
    "\n",
    "#### **Progress Monitoring**\n",
    "```python\n",
    "running_loss += loss.item()\n",
    "if i % 1000 == 999:\n",
    "    print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "    running_loss = 0.0\n",
    "```\n",
    "- **`running_loss`**: Tracks average loss over 1000 batches\n",
    "- **`% 1000 == 999`**: Print progress every 1000 batches\n",
    "- **Why monitor**: Helps us see if the AI is learning\n",
    "\n",
    "#### **What \"Loss\" Means**\n",
    "- **Low loss**: AI is making good predictions\n",
    "- **High loss**: AI is making many mistakes\n",
    "- **Decreasing loss**: AI is learning and improving\n",
    "- **Goal**: Get loss as low as possible\n",
    "\n",
    "#### **Real-World Analogy**\n",
    "Think of it like learning to ride a bike:\n",
    "1. **Try to ride**: Make predictions\n",
    "2. **Fall down**: Calculate loss (how bad was the attempt)\n",
    "3. **Adjust technique**: Update your approach\n",
    "4. **Try again**: Repeat until you can ride well\n",
    "\n",
    "**Real Impact**: This training process makes our AI smarter with each batch! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe34b4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üîç Step 6: Test the Model and See How It Performs\n",
    "Let‚Äôs check how well our model learned to recognize images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4f165",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üîç How do we test our AI model? (Click to Expand)</strong></summary>\n",
    "\n",
    "Testing is like giving our AI a final exam! Let's understand how it works:\n",
    "\n",
    "#### **Testing Process Breakdown**\n",
    "```python\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "```\n",
    "- **`correct`**: Counts how many predictions were right\n",
    "- **`total`**: Counts total number of images tested\n",
    "- **`torch.no_grad()`**: Tells PyTorch not to calculate gradients (we're not learning, just testing)\n",
    "\n",
    "#### **Testing Loop**\n",
    "```python\n",
    "for data in testloader:\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "```\n",
    "- **`testloader`**: Gives us test images (10,000 images the AI has never seen)\n",
    "- **`images`**: Test images to classify\n",
    "- **`labels`**: Correct answers (ground truth)\n",
    "- **`net(images)`**: AI makes predictions\n",
    "- **`torch.max()`**: Gets the category with highest probability\n",
    "\n",
    "#### **Accuracy Calculation**\n",
    "```python\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum().item()\n",
    "```\n",
    "- **`labels.size(0)`**: Number of images in this batch\n",
    "- **`predicted == labels`**: Compare predictions to correct answers\n",
    "- **`.sum().item()`**: Count how many were correct\n",
    "\n",
    "#### **Final Accuracy**\n",
    "```python\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')\n",
    "```\n",
    "- **Formula**: (Correct predictions / Total predictions) √ó 100\n",
    "- **Example**: 7,500 correct out of 10,000 = 75% accuracy\n",
    "\n",
    "#### **Why Testing is Important**\n",
    "- **Training accuracy**: How well AI performs on data it has seen\n",
    "- **Test accuracy**: How well AI performs on new, unseen data\n",
    "- **Generalization**: Good AI should work on new data, not just training data\n",
    "- **Overfitting**: If training accuracy >> test accuracy, AI memorized instead of learned\n",
    "\n",
    "#### **What Good Accuracy Looks Like**\n",
    "- **Random guessing**: 10% (since there are 10 categories)\n",
    "- **Beginner model**: 60-70% (our simple CNN)\n",
    "- **Professional model**: 90%+ (complex architectures)\n",
    "- **Human performance**: ~95% on CIFAR-10\n",
    "\n",
    "#### **Real-World Analogy**\n",
    "Think of it like a student taking a test:\n",
    "- **Training**: Student studies with practice problems\n",
    "- **Testing**: Student takes exam with new problems\n",
    "- **Good student**: Performs well on both practice and exam\n",
    "- **Bad student**: Memorizes practice problems but fails on exam\n",
    "\n",
    "**Real Impact**: Testing tells us if our AI can actually recognize new images! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7acd8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üëÄ Step 7: Visualize Model Predictions\n",
    "Let‚Äôs see what our AI predicts for a few test images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:  ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f8fc1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üëÄ How do we visualize AI predictions? (Click to Expand)</strong></summary>\n",
    "\n",
    "Visualization helps us see how well our AI is performing! Let's break it down:\n",
    "\n",
    "#### **Getting Test Images**\n",
    "```python\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "```\n",
    "- **`iter(testloader)`**: Creates an iterator for test data\n",
    "- **`next(dataiter)`**: Gets the next batch of test images\n",
    "- **`images`**: 8 test images to classify\n",
    "- **`labels`**: Correct answers for these images\n",
    "\n",
    "#### **Displaying Images**\n",
    "```python\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "```\n",
    "- **`make_grid(images)`**: Arranges 8 images in a grid\n",
    "- **`imshow()`**: Displays the image grid\n",
    "- **`GroundTruth`**: Shows the correct answers (what the images actually are)\n",
    "- **`classes[labels[j]]`**: Converts label numbers to category names\n",
    "\n",
    "#### **Making Predictions**\n",
    "```python\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "```\n",
    "- **`net(images.to(device))`**: AI makes predictions on the images\n",
    "- **`torch.max(outputs, 1)`**: Gets the category with highest probability\n",
    "- **`predicted`**: AI's guesses for each image\n",
    "\n",
    "#### **Displaying Predictions**\n",
    "```python\n",
    "print('Predicted:  ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n",
    "```\n",
    "- **`Predicted`**: Shows what the AI thinks each image is\n",
    "- **`classes[predicted[j]]`**: Converts prediction numbers to category names\n",
    "\n",
    "#### **How to Read the Results**\n",
    "- **GroundTruth**: The correct answers\n",
    "- **Predicted**: What the AI guessed\n",
    "- **Match**: When GroundTruth == Predicted, the AI got it right!\n",
    "- **Mismatch**: When they're different, the AI made a mistake\n",
    "\n",
    "#### **Example Output**\n",
    "```\n",
    "GroundTruth: plane  car    bird   cat    deer   dog    frog   horse\n",
    "Predicted:   plane  car    bird   cat    deer   dog    frog   horse\n",
    "```\n",
    "- **Perfect match**: AI got all 8 images correct!\n",
    "\n",
    "#### **Why Visualization Matters**\n",
    "- **See mistakes**: Understand what the AI struggles with\n",
    "- **Build confidence**: See the AI working correctly\n",
    "- **Debug issues**: Identify patterns in errors\n",
    "- **Share results**: Show others what the AI can do\n",
    "\n",
    "#### **Real-World Analogy**\n",
    "Think of it like a teacher grading a test:\n",
    "- **Test paper**: The images\n",
    "- **Answer key**: GroundTruth (correct answers)\n",
    "- **Student answers**: Predicted (AI's guesses)\n",
    "- **Grading**: Compare answers to see how well the student did\n",
    "\n",
    "**Real Impact**: Visualization helps us understand and trust our AI's performance! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2065b0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üß™ Step 8: Try Your Own Image! (Optional)\n",
    "You can upload your own small image and let the AI guess what it is.  \n",
    "Tip: The image should look like one of the 10 categories in CIFAR‚Äë10!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'  # example\n",
    "img = Image.open(requests.get(url, stream=True).raw).resize((32, 32))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "transform_single = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "\n",
    "net.eval()\n",
    "output = net(img_tensor)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"AI thinks this is a:\", classes[predicted[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f10fd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üì∏ How do we test with our own images? (Click to Expand)</strong></summary>\n",
    "\n",
    "Testing with custom images is like giving our AI a real-world challenge! Let's understand how it works:\n",
    "\n",
    "#### **Loading Custom Images**\n",
    "```python\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'\n",
    "img = Image.open(requests.get(url, stream=True).raw).resize((32, 32))\n",
    "```\n",
    "- **`PIL.Image`**: Python library for handling images\n",
    "- **`requests`**: Downloads images from the internet\n",
    "- **`.resize((32, 32))`**: Resizes image to match CIFAR-10 format\n",
    "- **Why resize**: Our AI was trained on 32√ó32 images\n",
    "\n",
    "#### **Displaying the Image**\n",
    "```python\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n",
    "- **`plt.imshow()`**: Shows the image\n",
    "- **`plt.axis('off')`**: Removes axis labels for cleaner display\n",
    "- **`plt.show()`**: Actually displays the image\n",
    "\n",
    "#### **Preprocessing for AI**\n",
    "```python\n",
    "transform_single = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "```\n",
    "- **`transform_single`**: Same preprocessing as training data\n",
    "- **`ToTensor()`**: Converts image to PyTorch tensor\n",
    "- **`Normalize()`**: Adjusts pixel values to match training\n",
    "- **`.unsqueeze(0)`**: Adds batch dimension (AI expects batches)\n",
    "- **`.to(device)`**: Moves to GPU/CPU\n",
    "\n",
    "#### **Making Predictions**\n",
    "```python\n",
    "net.eval()\n",
    "output = net(img_tensor)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"AI thinks this is a:\", classes[predicted[0]])\n",
    "```\n",
    "- **`net.eval()`**: Puts AI in evaluation mode (no learning)\n",
    "- **`net(img_tensor)`**: AI makes prediction\n",
    "- **`torch.max()`**: Gets the category with highest probability\n",
    "- **`classes[predicted[0]]`**: Converts number to category name\n",
    "\n",
    "#### **Why This is Important**\n",
    "- **Real-world testing**: See how AI performs on new images\n",
    "- **Validation**: Confirm the AI actually learned something useful\n",
    "- **Fun factor**: Makes the AI feel more interactive and engaging\n",
    "- **Debugging**: Identify what types of images confuse the AI\n",
    "\n",
    "#### **Tips for Better Results**\n",
    "- **Use clear images**: Blurry or dark images are harder to classify\n",
    "- **Match categories**: Images should look like CIFAR-10 categories\n",
    "- **Good lighting**: Well-lit images are easier to recognize\n",
    "- **Single object**: Images with one main object work better\n",
    "\n",
    "#### **Real-World Analogy**\n",
    "Think of it like a student taking a pop quiz:\n",
    "- **Training**: Student studies with textbook examples\n",
    "- **Custom image**: Teacher gives a new, unseen problem\n",
    "- **Prediction**: Student tries to solve it\n",
    "- **Result**: See if the student can apply what they learned\n",
    "\n",
    "**Real Impact**: This shows our AI can recognize real-world images, not just training data! üöÄ\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b560f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Step 9: Wrap-Up & What‚Äôs Next\n",
    "Amazing work! You just trained your **first image classification model**. üèÜ  \n",
    "In the next session, you‚Äôll learn how to build a **Chatbot** ü§ñ that can talk ‚Äî  \n",
    "and later combine it with your image AI to make your **AI Guessing Game**! üéÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579603d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß© Level Up! ‚Äì Mini Challenges\n",
    "\n",
    "Great job finishing your image classifier! üéâ  \n",
    "Now, let‚Äôs explore and experiment a little more. Each challenge below helps you think like an AI engineer. üë©‚Äçüíªüë®‚Äçüíª\n",
    "\n",
    "### 1Ô∏è‚É£ üß† Train Longer\n",
    "Increase the number of **epochs** in the training loop (for example, from `2` to `5` or `10`)  \n",
    "üëâ Does the accuracy improve? Does the training take longer?\n",
    "\n",
    "### 2Ô∏è‚É£ üé® Modify the Model\n",
    "Try changing the neural network structure ‚Äî for example:  \n",
    "- Add another convolutional layer  \n",
    "- Change the number of filters (e.g., from 6 to 8)  \n",
    "üëâ Observe how these changes affect performance.\n",
    "\n",
    "### 3Ô∏è‚É£ ‚öôÔ∏è Tune the Training Parameters\n",
    "Experiment with the **learning rate** or **batch size**:  \n",
    "```python\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "```\n",
    "üëâ What happens if you make the learning rate smaller or larger?\n",
    "\n",
    "### 4Ô∏è‚É£ üì∏ Use Your Own Images\n",
    "Collect 2‚Äì3 small photos from your phone or the internet (32√ó32 pixels recommended).  \n",
    "Try running them through the model ‚Äî does your AI guess correctly?\n",
    "\n",
    "### 5Ô∏è‚É£ üöÄ Bonus Challenge ‚Äì Advanced Dataset\n",
    "Replace CIFAR‚Äë10 with **CIFAR‚Äë100**, which has 100 categories instead of 10!  \n",
    "Hint: You only need to change one line in the dataset loading section.  \n",
    "üëâ Can your network handle it?\n",
    "\n",
    "\n",
    "\n",
    "These experiments will prepare you for **Session‚ÄØ4**, where you‚Äôll combine everything into a creative **AI Guessing Game! üéÆ**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c65dc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üåê Additional Resources & Further Learning\n",
    "\n",
    "## üß† Computer Vision & Image Classification\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Books & Articles</strong></summary>\n",
    "\n",
    "- **\"Deep Learning for Computer Vision\"** by Adrian Rosebrock\n",
    "- **\"Computer Vision: Algorithms and Applications\"** by Richard Szeliski\n",
    "- **\"Pattern Recognition and Machine Learning\"** by Christopher Bishop\n",
    "- **\"The Elements of Statistical Learning\"** by Hastie, Tibshirani, and Friedman\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üéì Online Courses</strong></summary>\n",
    "\n",
    "- **[CS231n - Convolutional Neural Networks](https://cs231n.stanford.edu)** - Stanford's famous computer vision course\n",
    "- **[Fast.ai - Practical Deep Learning](https://www.fast.ai)** - Hands-on deep learning course\n",
    "- **[Coursera - Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)** - Andrew Ng's comprehensive course\n",
    "- **[edX - Computer Vision](https://www.edx.org/course/computer-vision)** - MIT's computer vision course\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üõ†Ô∏è Technical Resources</strong></summary>\n",
    "\n",
    "- **[PyTorch Tutorials](https://pytorch.org/tutorials/)** - Official PyTorch learning materials\n",
    "- **[TensorFlow Tutorials](https://www.tensorflow.org/tutorials)** - Google's ML framework tutorials\n",
    "- **[OpenCV Tutorials](https://opencv.org/tutorials/)** - Computer vision library tutorials\n",
    "- **[Scikit-learn Documentation](https://scikit-learn.org/stable/)** - Machine learning library\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üé® Computer Vision Communities</strong></summary>\n",
    "\n",
    "- **[r/ComputerVision](https://reddit.com/r/ComputerVision)** - Reddit community\n",
    "- **[r/MachineLearning](https://reddit.com/r/MachineLearning)** - Reddit ML community\n",
    "- **[Computer Vision Slack](https://computervision.slack.com)** - Professional community\n",
    "- **[GitHub Computer Vision](https://github.com/topics/computer-vision)** - Open source projects\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üî¨ Research & News</strong></summary>\n",
    "\n",
    "- **[ArXiv Computer Vision](https://arxiv.org/list/cs.CV/recent)** - Latest CV research papers\n",
    "- **[Computer Vision News](https://www.computervision.news)** - Industry news and updates\n",
    "- **[The Gradient](https://thegradient.pub)** - AI research blog\n",
    "- **[Towards Data Science](https://towardsdatascience.com)** - Medium publication on AI/ML\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üéØ Specialized Topics</strong></summary>\n",
    "\n",
    "- **Object Detection**: Find and locate objects in images\n",
    "- **Image Segmentation**: Divide images into meaningful parts\n",
    "- **Face Recognition**: Identify and verify human faces\n",
    "- **Medical Imaging**: AI for healthcare and diagnosis\n",
    "- **Autonomous Vehicles**: Computer vision for self-driving cars\n",
    "\n",
    "</details>\n",
    "\n",
    "**Remember**: Computer vision is a powerful tool that can recognize and understand the visual world around us! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
