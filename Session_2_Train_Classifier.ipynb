{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014438b1",
   "metadata": {},
   "source": [
    "# Big Project – Session 2: Train Image Classifier\n",
    "Train a small classifier (ResNet18) and save it to `game_project/models/classifier.pt`.\n",
    "\n",
    "You can start with CIFAR-10 for speed, then optionally fine-tune on your own assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip -q install torch torchvision matplotlib --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import torchvision, torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import os, json, time, matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SAVE_PATH = \"/mnt/data/nicegpu_ai_workshop/game_project/models/classifier.pt\"\n",
    "CLASSES_PATH = \"/mnt/data/nicegpu_ai_workshop/game_project/models/classes.txt\"\n",
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
    "print('Saving model to:', SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d5a32",
   "metadata": {},
   "source": [
    "### Option A: CIFAR-10 (fast & simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33839e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128; EPOCHS=2; LR=1e-3\n",
    "train_tfms=T.Compose([T.RandomCrop(32,padding=4), T.RandomHorizontalFlip(), T.ToTensor()])\n",
    "test_tfms=T.Compose([T.ToTensor()])\n",
    "train_ds=torchvision.datasets.CIFAR10('./data', train=True, transform=train_tfms, download=True)\n",
    "test_ds=torchvision.datasets.CIFAR10('./data', train=False, transform=test_tfms, download=True)\n",
    "classes=train_ds.classes\n",
    "open(CLASSES_PATH,'w').write(\"\\n\".join(classes))\n",
    "\n",
    "train_dl=DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=2,pin_memory=True)\n",
    "test_dl=DataLoader(test_ds,batch_size=BATCH_SIZE,shuffle=False,num_workers=2,pin_memory=True)\n",
    "\n",
    "model=resnet18(num_classes=len(classes)).to(DEVICE)\n",
    "crit=nn.CrossEntropyLoss(); opt=optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "for e in range(1,EPOCHS+1):\n",
    "    model.train(); tot=0; correct=0; loss_sum=0\n",
    "    t0=time.time()\n",
    "    for x,y in train_dl:\n",
    "        x,y=x.to(DEVICE),y.to(DEVICE)\n",
    "        opt.zero_grad(); out=model(x); loss=crit(out,y); loss.backward(); opt.step()\n",
    "        loss_sum+=loss.item()*x.size(0); correct+=(out.argmax(1)==y).sum().item(); tot+=x.size(0)\n",
    "    print(f\"Epoch {e}/{EPOCHS} | loss={loss_sum/tot:.4f} acc={correct/tot:.3f} time={time.time()-t0:.1f}s\")\n",
    "\n",
    "# Evaluate\n",
    "model.eval(); tot=0; correct=0\n",
    "with torch.no_grad():\n",
    "    for x,y in test_dl:\n",
    "        x,y=x.to(DEVICE),y.to(DEVICE)\n",
    "        out=model(x); pred=out.argmax(1); correct+=(pred==y).sum().item(); tot+=x.size(0)\n",
    "print('Test accuracy:', correct/tot)\n",
    "\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "print('✅ Saved model to', SAVE_PATH)\n",
    "print('✅ Saved classes to', CLASSES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76ae32",
   "metadata": {},
   "source": [
    "### Option B (Optional): Fine-tune on your own assets\n",
    "Create folders like `my_assets/classA/*.png`, `my_assets/classB/*.png`, then run below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "own_root = Path(\"my_assets\")  # put your labeled folders here\n",
    "if own_root.exists():\n",
    "    print(\"Found:\", own_root)\n",
    "    tfms = T.Compose([T.Resize((32,32)), T.ToTensor()])\n",
    "    own_ds = torchvision.datasets.ImageFolder(own_root, transform=tfms)\n",
    "    own_dl = DataLoader(own_ds, batch_size=64, shuffle=True)\n",
    "    # quick single-epoch fine-tune\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(own_ds.classes)).to(DEVICE)\n",
    "    opt = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    for x,y in own_dl:\n",
    "        x,y=x.to(DEVICE),y.to(DEVICE)\n",
    "        opt.zero_grad(); out=model(x); loss=crit(out,y); loss.backward(); opt.step()\n",
    "    # save new head + classes\n",
    "    with open(CLASSES_PATH,'w') as f: f.write(\"\\n\".join(own_ds.classes))\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    print(\"✅ Fine-tuned on custom assets and saved model.\")\n",
    "else:\n",
    "    print(\"Optional: add labeled images to ./my_assets/ to fine-tune.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
