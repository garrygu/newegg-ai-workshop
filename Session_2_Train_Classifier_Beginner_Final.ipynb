{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0d54a5",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Session 2: Train Your Own Image Classifier (Beginner Level)\n",
    "\n",
    "Welcome to **Session 2** of Newegg‚Äôs *AI Foundations Workshop*! üéì  \n",
    "In this session, you‚Äôll **teach an AI to recognize images** ‚Äî just like how your phone camera knows what‚Äôs a cat or a car!  \n",
    "We‚Äôll use **PyTorch** and a fun dataset called **CIFAR‚Äë10**, which contains 10 types of small color images.\n",
    "\n",
    "By the end, you‚Äôll have a mini AI model that can recognize images ‚Äî a key skill for building your final **AI Game** in Session 4. üéÆ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2041033",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ What You‚Äôll Learn\n",
    "- How image classification works  \n",
    "- How to train and test a simple AI model  \n",
    "- How to visualize and understand model predictions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d185f0",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Step 1: Setup Your Environment\n",
    "Let‚Äôs import the libraries we need. If any are missing, you can install them by running:\n",
    "```bash\n",
    "pip install torch torchvision matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852874eb",
   "metadata": {},
   "source": [
    "\n",
    "## üñºÔ∏è Step 2: Load and Explore the CIFAR‚Äë10 Dataset\n",
    "The CIFAR‚Äë10 dataset has 60,000 color images in 10 classes (airplane, car, bird, cat, etc.).  \n",
    "Each image is only 32√ó32 pixels ‚Äî perfect for quick training! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform: convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download and load training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Helper function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5eea5",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Step 3: Build a Simple Neural Network\n",
    "We‚Äôll build a small **Convolutional Neural Network (CNN)** ‚Äî a type of model that‚Äôs great for recognizing images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2922a",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Step 4: Define Loss Function and Optimizer\n",
    "The **loss function** measures how wrong the AI is, and the **optimizer** helps it learn from mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5ec97",
   "metadata": {},
   "source": [
    "\n",
    "## üöÄ Step 5: Train the Classifier\n",
    "Now we‚Äôll train the AI using the training images.  \n",
    "This will take a few minutes depending on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37555e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(2):  # run for 2 epochs for demo\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('‚úÖ Training complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777be118",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Step 6: Test the Model and See How It Performs\n",
    "Let‚Äôs check how well our model learned to recognize images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e97002",
   "metadata": {},
   "source": [
    "\n",
    "## üëÄ Step 7: Visualize Model Predictions\n",
    "Let‚Äôs see what our AI predicts for a few test images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:  ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681af8dd",
   "metadata": {},
   "source": [
    "\n",
    "## üß™ Step 8: Try Your Own Image! (Optional)\n",
    "You can upload your own small image and let the AI guess what it is.  \n",
    "Tip: The image should look like one of the 10 categories in CIFAR‚Äë10!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'  # example\n",
    "img = Image.open(requests.get(url, stream=True).raw).resize((32, 32))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "transform_single = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "\n",
    "net.eval()\n",
    "output = net(img_tensor)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"AI thinks this is a:\", classes[predicted[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d1ef5",
   "metadata": {},
   "source": [
    "\n",
    "## üéâ Step 9: Wrap-Up & What‚Äôs Next\n",
    "Amazing work! You just trained your **first image classification model**. üèÜ  \n",
    "In the next session, you‚Äôll learn how to build a **Chatbot** ü§ñ that can talk ‚Äî  \n",
    "and later combine it with your image AI to make your **AI Guessing Game**! üéÆ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579603d",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Level Up! ‚Äì Mini Challenges\n",
    "\n",
    "Great job finishing your image classifier! üéâ  \n",
    "Now, let‚Äôs explore and experiment a little more. Each challenge below helps you think like an AI engineer. üë©‚Äçüíªüë®‚Äçüíª\n",
    "\n",
    "### 1Ô∏è‚É£ üß† Train Longer\n",
    "Increase the number of **epochs** in the training loop (for example, from `2` to `5` or `10`)  \n",
    "üëâ Does the accuracy improve? Does the training take longer?\n",
    "\n",
    "### 2Ô∏è‚É£ üé® Modify the Model\n",
    "Try changing the neural network structure ‚Äî for example:  \n",
    "- Add another convolutional layer  \n",
    "- Change the number of filters (e.g., from 6 to 8)  \n",
    "üëâ Observe how these changes affect performance.\n",
    "\n",
    "### 3Ô∏è‚É£ ‚öôÔ∏è Tune the Training Parameters\n",
    "Experiment with the **learning rate** or **batch size**:  \n",
    "```python\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "```\n",
    "üëâ What happens if you make the learning rate smaller or larger?\n",
    "\n",
    "### 4Ô∏è‚É£ üì∏ Use Your Own Images\n",
    "Collect 2‚Äì3 small photos from your phone or the internet (32√ó32 pixels recommended).  \n",
    "Try running them through the model ‚Äî does your AI guess correctly?\n",
    "\n",
    "### 5Ô∏è‚É£ üöÄ Bonus Challenge ‚Äì Advanced Dataset\n",
    "Replace CIFAR‚Äë10 with **CIFAR‚Äë100**, which has 100 categories instead of 10!  \n",
    "Hint: You only need to change one line in the dataset loading section.  \n",
    "üëâ Can your network handle it?\n",
    "\n",
    "---\n",
    "\n",
    "These experiments will prepare you for **Session‚ÄØ4**, where you‚Äôll combine everything into a creative **AI Guessing Game! üéÆ**\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
