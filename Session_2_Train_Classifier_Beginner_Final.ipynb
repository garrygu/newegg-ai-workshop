{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0d54a5",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ§  Session 2: Train Your Own Image Classifier (Beginner Level)\n",
    "\n",
    "Welcome to **Session 2** of Neweggâ€™s *AI Foundations Workshop*! ğŸ“  \n",
    "In this session, youâ€™ll **teach an AI to recognize images** â€” just like how your phone camera knows whatâ€™s a cat or a car!  \n",
    "Weâ€™ll use **PyTorch** and a fun dataset called **CIFARâ€‘10**, which contains 10 types of small color images.\n",
    "\n",
    "By the end, youâ€™ll have a mini AI model that can recognize images â€” a key skill for building your final **AI Game** in Session 4. ğŸ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2041033",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ¯ What Youâ€™ll Learn\n",
    "- How image classification works  \n",
    "- How to train and test a simple AI model  \n",
    "- How to visualize and understand model predictions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d185f0",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 1: Setup Your Environment\n",
    "Letâ€™s import the libraries we need. If any are missing, you can install them by running:\n",
    "```bash\n",
    "pip install torch torchvision matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852874eb",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ–¼ï¸ Step 2: Load and Explore the CIFARâ€‘10 Dataset\n",
    "The CIFARâ€‘10 dataset has 60,000 color images in 10 classes (airplane, car, bird, cat, etc.).  \n",
    "Each image is only 32Ã—32 pixels â€” perfect for quick training! ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform: convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download and load training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Helper function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5eea5",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§© Step 3: Build a Simple Neural Network\n",
    "Weâ€™ll build a small **Convolutional Neural Network (CNN)** â€” a type of model thatâ€™s great for recognizing images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2922a",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 4: Define Loss Function and Optimizer\n",
    "The **loss function** measures how wrong the AI is, and the **optimizer** helps it learn from mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5ec97",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸš€ Step 5: Train the Classifier\n",
    "Now weâ€™ll train the AI using the training images.  \n",
    "This will take a few minutes depending on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37555e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(2):  # run for 2 epochs for demo\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('âœ… Training complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777be118",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ” Step 6: Test the Model and See How It Performs\n",
    "Letâ€™s check how well our model learned to recognize images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e97002",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ‘€ Step 7: Visualize Model Predictions\n",
    "Letâ€™s see what our AI predicts for a few test images!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:  ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681af8dd",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§ª Step 8: Try Your Own Image! (Optional)\n",
    "You can upload your own small image and let the AI guess what it is.  \n",
    "Tip: The image should look like one of the 10 categories in CIFARâ€‘10!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'  # example\n",
    "img = Image.open(requests.get(url, stream=True).raw).resize((32, 32))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "transform_single = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "img_tensor = transform_single(img).unsqueeze(0).to(device)\n",
    "\n",
    "net.eval()\n",
    "output = net(img_tensor)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(\"AI thinks this is a:\", classes[predicted[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d1ef5",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ‰ Step 9: Wrap-Up & Whatâ€™s Next\n",
    "Amazing work! You just trained your **first image classification model**. ğŸ†  \n",
    "In the next session, youâ€™ll learn how to build a **Chatbot** ğŸ¤– that can talk â€”  \n",
    "and later combine it with your image AI to make your **AI Guessing Game**! ğŸ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579603d",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§© Level Up! â€“ Mini Challenges\n",
    "\n",
    "Great job finishing your image classifier! ğŸ‰  \n",
    "Now, letâ€™s explore and experiment a little more. Each challenge below helps you think like an AI engineer. ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»\n",
    "\n",
    "### 1ï¸âƒ£ ğŸ§  Train Longer\n",
    "Increase the number of **epochs** in the training loop (for example, from `2` to `5` or `10`)  \n",
    "ğŸ‘‰ Does the accuracy improve? Does the training take longer?\n",
    "\n",
    "### 2ï¸âƒ£ ğŸ¨ Modify the Model\n",
    "Try changing the neural network structure â€” for example:  \n",
    "- Add another convolutional layer  \n",
    "- Change the number of filters (e.g., from 6 to 8)  \n",
    "ğŸ‘‰ Observe how these changes affect performance.\n",
    "\n",
    "### 3ï¸âƒ£ âš™ï¸ Tune the Training Parameters\n",
    "Experiment with the **learning rate** or **batch size**:  \n",
    "```python\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "```\n",
    "ğŸ‘‰ What happens if you make the learning rate smaller or larger?\n",
    "\n",
    "### 4ï¸âƒ£ ğŸ“¸ Use Your Own Images\n",
    "Collect 2â€“3 small photos from your phone or the internet (32Ã—32 pixels recommended).  \n",
    "Try running them through the model â€” does your AI guess correctly?\n",
    "\n",
    "### 5ï¸âƒ£ ğŸš€ Bonus Challenge â€“ Advanced Dataset\n",
    "Replace CIFARâ€‘10 with **CIFARâ€‘100**, which has 100 categories instead of 10!  \n",
    "Hint: You only need to change one line in the dataset loading section.  \n",
    "ğŸ‘‰ Can your network handle it?\n",
    "\n",
    "---\n",
    "\n",
    "These experiments will prepare you for **Sessionâ€¯4**, where youâ€™ll combine everything into a creative **AI Guessing Game! ğŸ®**\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
